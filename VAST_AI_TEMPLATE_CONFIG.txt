==========================================
VAST.AI TEMPLATE CONFIGURATION
LLM RAG Multi-Tenant Platform
==========================================

Copy and paste these settings into your vast.ai template:

───────────────────────────────────────────
1. DOCKER IMAGE PATH
───────────────────────────────────────────
docker.io/vastai/kvm:@vastai-automatic-tag

───────────────────────────────────────────
2. PORTS
───────────────────────────────────────────
5000:5000
3000:3000
19530:19530
9091:9091

───────────────────────────────────────────
3. DOCKER OPTIONS
───────────────────────────────────────────
--shm-size=16g --gpus all -v /root:/workspace

───────────────────────────────────────────
4. ENVIRONMENT VARIABLES
───────────────────────────────────────────
DATABASE_URL=sqlite:///./instance/llm_rag.db
MILVUS_HOST=localhost
MILVUS_PORT=19530
VLLM_BASE_URL=http://localhost:8000
TRITON_BASE_URL=http://localhost:8001
ADAPTER_BASE_PATH=/workspace/LLM_RAG/LLM-Finetuner-main/adapters
BYPASS_LOGIN=true
FLASK_APP=app_new.py
PORT=5000
CUDA_AVAILABLE=true
GUNICORN_WORKERS=4
REACT_APP_API_HOST=http://localhost:5000
REACT_APP_BYPASS_LOGIN=true
REACT_APP_GOOGLE_CLIENT_ID=
NODE_ENV=production

───────────────────────────────────────────
5. ON-START SCRIPT
───────────────────────────────────────────
LEAVE EMPTY - We'll deploy manually after instance starts

───────────────────────────────────────────
6. LAUNCH MODE
───────────────────────────────────────────
Command: (leave empty or use: /bin/bash)

───────────────────────────────────────────
7. EXTRA FILTERS
───────────────────────────────────────────
gpu_name:RTX 5090
gpu_name:RTX 5070 Ti
gpu_name:RTX 4090
gpu_name:RTX 4080
gpu_name:A100
gpu_name:A6000

───────────────────────────────────────────
8. DISK SPACE
───────────────────────────────────────────
Minimum: 50 GB
Recommended: 100 GB

───────────────────────────────────────────
9. ACCESS SETTINGS
───────────────────────────────────────────
Jupyter: (Optional - not required)
SSH: Enabled (Required for debugging)

───────────────────────────────────────────
10. AFTER CREATING TEMPLATE - DEPLOYMENT STEPS
───────────────────────────────────────────

STEP 1: Create Template
  ✓ Fill in all fields above (leave On-start Script EMPTY)
  ✓ Click "Save Template"
  ✓ Select a GPU instance and click "RENT"

STEP 2: Connect to Instance
  ✓ Wait for instance to start (1-2 minutes)
  ✓ Copy SSH command from vast.ai dashboard
  ✓ SSH into the instance:
    ssh -p <PORT> root@<IP>

STEP 3: Run Deployment
  Option A - Use deployment script (recommended):
    curl -fsSL https://raw.githubusercontent.com/dragon-dev-01/LLM_RAG/main/vast_ai_onstart.sh | bash

  Option B - Manual deployment (see commands below)

STEP 4: Wait for Completion
  ✓ First deployment takes 5-10 minutes
  ✓ Watch for "✅ Deployment Complete!" message
  ✓ Services available at:
    • Backend API:  http://<INSTANCE_IP>:5000
    • Frontend UI:  http://<INSTANCE_IP>:3000
    • Milvus Health: http://<INSTANCE_IP>:9091/healthz

───────────────────────────────────────────
MANUAL DEPLOYMENT COMMANDS
───────────────────────────────────────────

# Install system dependencies
apt-get update -y
apt-get install -y python3 python3-pip python3-venv git curl wget build-essential docker.io docker-compose nodejs npm screen sqlite3 libpq-dev poppler-utils tesseract-ocr libtesseract-dev libgl1-mesa-glx libglib2.0-0
curl -fsSL https://deb.nodesource.com/setup_18.x | bash - && apt-get install -y nodejs

# Clone repository
cd /root && git clone https://github.com/dragon-dev-01/LLM_RAG.git LLM_RAG || (cd LLM_RAG && git pull)

# Start MilvusDB
cd /root/LLM_RAG/LLM-Finetuner-main && docker-compose up -d
sleep 30

# Setup Python backend
cd /root/LLM_RAG/LLM-Finetuner-main
python3 -m venv venv
/root/LLM_RAG/LLM-Finetuner-main/venv/bin/pip install --upgrade pip setuptools wheel
/root/LLM_RAG/LLM-Finetuner-main/venv/bin/pip install -r requirements.txt gunicorn

# Create directories
mkdir -p uploads adapters logs instance

# Initialize database
export DATABASE_URL=sqlite:///./instance/llm_rag.db
export MILVUS_HOST=localhost
export MILVUS_PORT=19530
export BYPASS_LOGIN=true
export FLASK_APP=app_new.py
export PORT=5000
cd /root/LLM_RAG/LLM-Finetuner-main
/root/LLM_RAG/LLM-Finetuner-main/venv/bin/python3 -m flask db upgrade || /root/LLM_RAG/LLM-Finetuner-main/venv/bin/python3 -c "from src import db, create_app; app = create_app(); app.app_context().push(); db.create_all()"
/root/LLM_RAG/LLM-Finetuner-main/venv/bin/python3 scripts/init_base_models.py || touch .base_models_initialized

# Setup frontend
cd /root/LLM_RAG/LLM-Finetuner-FE-main
npm install --legacy-peer-deps
echo "REACT_APP_API_HOST=http://localhost:5000" > .env
echo "REACT_APP_BYPASS_LOGIN=true" >> .env
echo "PORT=3000" >> .env

# Start backend
cd /root/LLM_RAG/LLM-Finetuner-main
screen -dmS backend bash -c "export DATABASE_URL=sqlite:///./instance/llm_rag.db && export MILVUS_HOST=localhost && export MILVUS_PORT=19530 && export BYPASS_LOGIN=true && export PORT=5000 && /root/LLM_RAG/LLM-Finetuner-main/venv/bin/gunicorn -w 4 -b 0.0.0.0:5000 --timeout 300 app_new:app"

# Start frontend
sleep 5
cd /root/LLM_RAG/LLM-Finetuner-FE-main
screen -dmS frontend bash -c "BROWSER=none npm start"

# Check status
sleep 10
echo "✅ Deployment Complete!"
echo "Backend: http://localhost:5000"
echo "Frontend: http://localhost:3000"

───────────────────────────────────────────
USEFUL COMMANDS
───────────────────────────────────────────

View logs:
  screen -r backend   # Backend logs (Ctrl+A then D to detach)
  screen -r frontend  # Frontend logs

Test API:
  curl http://localhost:5000/api/base-models

Restart services:
  screen -r backend   # Ctrl+C, then restart command
  screen -r frontend # Ctrl+C, then restart command

Stop services:
  pkill -f gunicorn
  pkill -f "npm start"

───────────────────────────────────────────
NOTES
───────────────────────────────────────────

1. First deployment takes 5-10 minutes for:
   - System package installation
   - Python/Node dependencies
   - MilvusDB initialization

2. Services run in screen sessions for easy log access

3. Bypass login is enabled by default for testing.
   To use Google OAuth, set BYPASS_LOGIN=false and
   provide REACT_APP_GOOGLE_CLIENT_ID.

==========================================

